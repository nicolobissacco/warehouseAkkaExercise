service: "warehouse-exercise"

ask.timeout = 25s

custom-downing {
  stable-after = 20s

  oldest-auto-downing {
    oldest-member-role = ""
    down-if-alone = true
  }
}

akka {
  jvm-exit-on-fatal-error = false
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  logger-startup-timeout = 30s
  loglevel = "DEBUG"
  log-config-on-start = "off"
  log-dead-letters = 100
  log-dead-letters-during-shutdown = off

  actor {
    debug {
      receive = on
      autoreceive = on
      lifecycle = on
      unhandled = on
    }
    // cluster
    provider = cluster
    // persistence
    extensions = [akka.persistence.Persistence]
    // serialization
    allow-java-serialization = on
    serializers.proto = "akka.remote.serialization.ProtobufSerializer"
    serialization-bindings {
      "java.io.serializable" = none
    }
  }

  remote {
    enabled-transports = ["akka.remote.netty.tcp"]
    netty.tcp {
      hostname = "127.0.0.1"
      # hostname = ${?HOSTNAME}
      port = 2551
      # bind-hostname = 0.0.0.0
      # bind-port = 2551
    }
    log-remote-lifecycle-events = DEBUG
  }

  cluster {
    seed-nodes = ["akka.tcp://"${service}"@"${akka.remote.netty.tcp.hostname}":"${akka.remote.netty.tcp.port}]

    failure-detector {
      acceptable-heartbeat-pause = 20s
      hearbeat-interval = 2s
      threshold = 10.0
    }
    sharding {
      remember-entities = on
      updating-state-timeout = 10s
      state-store-mode = persistence
    }
  }

  persistence {
    journal {
      auto-start-journals = [""]
      plugin = cassandra-journal
      #plugin = inmemory-journal
    }

    snapshot-store {
      plugin = cassandra-snapshot-store
      #plugin = inmemory-snapshot-store
    }

    provider = cluster

  }
}

inmemory-read-journal {
  # Absolute path to the write journal plugin configuration section to get the event adapters from
  write-plugin = "inmemory-journal"

  # there are two modes; sequence or uuid. If set to "sequence" and NoOffset will be requested, then
  # the query will return Sequence offset types. If set to "uuid" and NoOffset will be requested, then
  # the query will return Offset offset types. When the query is called with Sequence then
  # the query will return Sequence offset types and if the query is called with TimeBasedUUID types then
  # the query will return TimeBasedUUID offset types.
  offset-mode = "uuid"

  # ask timeout on Futures
  ask-timeout = "10s"

  # New events are retrieved (polled) with this interval.
  refresh-interval = "100ms"

  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = "5000"
}

inmemory-journal {
  circuit-breaker {
    max-failures = 10
    call-timeout = 600s
    reset-timeout = 30s
  }
}

cassandra-journal {
  # Comma-separated list of contact points in the cluster.
  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1
  # Write consistency level
  write-consistency = "ONE"
  # Read consistency level
  read-consistency = "ONE"

  contact-points = ["localhost"]
  port = 9042

  keyspace = "local_warehouse_exercise_journal"

  event-adapters {
    warehouse-tagging-adapter = "warehouse.actors.adapter.WarehouseAdapter"
    supplier-tagging-adapter = "warehouse.actors.adapter.SupplierAdapter"
  }
  event-adapter-bindings {
    "warehouse.domain.Warehouse$Created" = warehouse-tagging-adapter
    "warehouse.domain.Warehouse$AddedProduct" = warehouse-tagging-adapter
    "warehouse.domain.Warehouse$RemovedProduct" = warehouse-tagging-adapter
    "warehouse.domain.Supplier$Created" = supplier-tagging-adapter
  }

  # Number of retries before giving up connecting to the cluster
  connect-retries = 20
  # Delay between connection retries
  connect-retry-delay = 5s
  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1
  # Write consistency level
  write-consistency = "ONE"
  # Read consistency level
  read-consistency = "ONE"

  events-by-tag {
    # Tagged events are written to a separate Cassandra table in unlogged batches
    # Max size of these batches. The best value for this will depend on the size of
    # the serialized events. Cassandra logs a warniprintln(">>>extractEntityId",m.warehouseId)ng for batches above a certain
    # size and this should be reduced if that warning is seen.
    max-message-batch-size = 50
  }
}

cassandra-query-journal {
  refresh-interval = 100ms
}

cassandra-snapshot-store {
  # Comma-separated list of contact points in the cluster.
  contact-points = ["localhost"]
  port = 9042

  keyspace = "local_warehouse_exercise_snapshot"

  # Number of retries before giving up connecting to the cluster
  connect-retries = 20
  # Delay between connection retries
  connect-retry-delay = 5s

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 3
  # Write consistency level
  write-consistency = "ONE"
  # Read consistency level
  read-consistency = "ONE"
}

read-side {
  batch {
    size = 1000
    size = ${?CASSANDRA_BATCH_SIZE}
    window = 500ms
    window = ${?CASSANDRA_BATCH_WINDOW}
  }
  delay = 5s
}

warehouse-exercise-blocking-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    fixed-pool-size: 2
    fixed-pool-size: ${?BLOCKING_THREAD_POOL_SIZE}
  }
  throughput = 1
}

http {
  interface = "127.0.0.1"
  port = 9000
}